---
title: "MDI: weeks 1 to 3"
author: "Stephen Coleman"
date: "20 February 2019"
output: html_document
bibliography: weeks_123_bib.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Prelude

Many of the R snippets below require these R packages [@kolde2019pheatmap, @dowle2019data, @neuwirth2014rcolorbrewer]:

```{r libraries}
library(pheatmap)
library(data.table)
library(RColorBrewer)
```

## MDI

### Reading
Inital work involved reading @mason2016mdi and reading the manual of the associated program. Expecting that this would have difficulties scaling (based on Paul's beliefs from November) to nine datasets I also looked into @bardenet2017markov for general ideas, but more specifically read a good chunk of @betancourt2017conceptual. These topics were of interest as I know the MDI implementation uses a Gibbs sampler - I hoped we could make gains in the computational trtactability of using all 9 datasets in one go with a more clever sampling method.


### Data handling
MDI uses data that has common row names across all datasets. The data from [the CEDAR cohort](http://139.165.108.18/srv/genmol/permanent/1be6993fe41c12a051c9244d67c91da2be49e5dd26a6cd79f442bc006971e2ef/crohn-index.html) is in the form of [people $\times$ probes]. We want to transpose this; to accomplish this task we wrote [an Rscript](https://github.com/stcolema/ra_chris_wallace/blob/master/matrix_transposer.R) that can be called form the Linux command line with appropriate arguments to transpose .csv files in a given directory. The `data.table` package by @dowle2019data was of great use in making this quick to call - for our 9 datasets of ~300 people and 8-16 thousand probes it took less than a minute to convert the files.

Another [script was required to remove all the non-ubiquitous probe IDs](https://github.com/stcolema/ra_chris_wallace/blob/master/common_rownames_data.R). Any probe not present in all datasets was removed to allow MDI to perform as MDI cannot handle missing data. This reduced the set of probes to 4,964.

We performed MDI on these 9 reduced datasets with 10,000 iterations, a burn-in of 1,000 and a thinning rate of 25. MDI overfits the clustering problem beginning with 50 clusters; this reduced down to around 10 occupied clusters per dataset. We assumed that the median cluster allocation was the predicted cluster forgetting about the **label-flipping** problem of unsupervised methods.

We constructed a dataframe of the median allocation per dataset for each probe. The probes are translated to the associated gene using the [key available online](http://139.165.108.18/srv/genmol/permanent/1be6993fe41c12a051c9244d67c91da2be49e5dd26a6cd79f442bc006971e2ef/CEDAR_GE/Probes_good_reanno_31137_TSS.txt). As some of the probes mapped to non-unique genes we use a matrix to hold our data (as this does not require unique row names). We read this in and visually inspect the head of the data.

```{r mdi_1_alloc_data}
# Read in the data and convert to a matrix with apporpriate row names
compare_df <- data.table::fread("~/Desktop/MDI/Runs/Run 1/allocation_data_run_1.csv")
compare_df_mat <- as.matrix(compare_df[, -10])
row.names(compare_df_mat) <- compare_df$V1

# Inspect the data
head(compare_df_mat)
```

Using this data we generated a heatmap.

```{r mdi_1_heatmap, echo = FALSE}
col_pal <- c("#DDDDDD", rev(RColorBrewer::brewer.pal(n = 11, "RdYlBu")))

ph_full <- pheatmap::pheatmap(compare_df_mat,
 cluster_cols = F,
 color = col_pal,
 main = "Heatmap for common probes"
)

```

There are 14 clusters present here; to enable comparison we went for a wider colour palette. This is the reason for the garishness of this heatplot. There is appears to have lower similarity than one might expect, particularly considering the selection of data - we only include the probes that are sufficiently expressed in each cell type to register for measurement. Possibly this is an artifact of not considering label-flipping. 

With the same allocation data and maintaining the ordering from the heatmap of the full dataset we inspect subsamples of the data.

```{r mdi_1_small_heatmaps, echo = FALSE}
row_order <- ph_full$tree_row[["order"]]

df_ph_order <- compare_df_mat[row_order, ]

pheatmap(df_ph_order[1:1000, ],
         cluster_rows = F, 
         cluster_cols = F,
         color = col_pal,
         main = "Entries 1:1000")

pheatmap(df_ph_order[1001:2000, ],
         cluster_rows = F, 
         cluster_cols = F, 
         color = col_pal,
         main = "Entries 1001:2000")

pheatmap(df_ph_order[2001:3000, ], 
         cluster_rows = F, 
         cluster_cols = F, 
         color = col_pal,
         main = "Entries 2001:3000")

pheatmap(df_ph_order[3001:4000, ], 
         cluster_rows = F, 
         cluster_cols = F, 
         color = col_pal,
         main = "Entries 3001:4000")

pheatmap(df_ph_order[4001:4964, ], 
         cluster_rows = F,
         cluster_cols = F, 
         color = col_pal,
         main = "Entries 4001:4964")

```

With this increased granularity, we see that after the first 1,000 rows the similarity across tissues becomes greater. There is still large sections of dissimilarity, but the clustering more coherent than the first plot suggests. Notice also that the PLA dataset (platelets) is the greatest source of dissimialrity - this is also the thinnest dataset with only 8 thousand probes present in the full format. 

Please note that these following heatmaps have **unique** clusterings and have not inherited the clustering of the original heatmap unlike thpse preceding this section.

```{r no_platelets, echo = FALSE}
pheatmap::pheatmap(compare_df_mat[, -7],
 cluster_cols = F,
 color = col_pal,
 main = "Heatmap for common probes excluding PLA"
)
```

We consider only four most similar datasets, CD14, CD4, CD8, RE and TR.
 
```{r sim_heatmaps, echo = FALSE}
pheatmap::pheatmap(compare_df_mat[, -c(2, 3, 6, 7)],
 cluster_cols = F,
 color = col_pal,
 main = "Heatmap for datasets of greatest similarity"
)
```

Out of curiousity we check the clustering and heatmap for the excluded datasets.

```{r dis_heatmaps, echo = FALSE}
pheatmap::pheatmap(compare_df_mat[, c(2, 3, 6, 7)],
 cluster_cols = F,
 color = col_pal,
 main = "Heatmap for datasets of least similarity"
)
```

This is sligthly more coherent than our first heatmap where we considered all datasets at once - this suggests that trying to process the output of all 9 datasets at once is not optimal and is in itself a non-trivial task (particulalrly if label-flipping cannot be ignored).

## Including all probes
Next we attempt to include all probes present across the 9 datasets. The challenge here is to include the probes in such a fashion as to not add noise to the final clustering. To do this we first inspect the spread of the expression values in the datasets. As this is too large to consider in normal summary statistics, we inspect histograms of these - we notice that all of the probe expression values have very similar means and standard deviations - these are densely (i.e. within 1.0 for the mean, within 0.2 for the standard deviation) distributed around 7.0 and 2.10 respectively.

We thus write [an Rscript](https://github.com/stcolema/ra_chris_wallace/blob/master/finad_all_probe_ids.R) that finds the list of all unique probe IDs present across the 9 datasets and adds the required rows to each .csv file (filled with 0's but any arbitrarily distant number from the range inhabitated by the actual measurements should be acceptable) and rearranging to have common row names and row orders in each dataset for all 18,900 prob IDs. Using these new datasets we perform MDI with the same arguments. This script also saves a binary matrix indicating for each probe which datasets it is present in. We will use this later as part of a sense check.

# References
